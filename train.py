# -*- coding: utf-8 -*-
"""train
Automatically generated by Colab.
Original file is located at
    https://colab.research.google.com/drive/1zQ2lyKuqyaS7FEqsIXXVRdmjpTPRBSQN
"""

import os

# ğŸ”¹ COCO ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ ì¡´ì¬ ì‹œ ìƒëµ)
if not os.path.exists("train2014"):
    os.system("pip install -q gdown")
    os.system("gdown --id 1FpLRZMeh2VL4pRjt5MVoZbTIhaJT4SOr")
    os.system("unzip -q train2014.zip -d train2014")
else:
    print("âœ… train2014 ë””ë ‰í† ë¦¬ ì¡´ì¬ - ë‹¤ìš´ë¡œë“œ ìƒëµ")

# ğŸ”¹ ì§ˆë¬¸/ì •ë‹µ JSON ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ ì¡´ì¬ ì‹œ ìƒëµ)
if not os.path.exists("v2_OpenEnded_mscoco_train2014_questions.json"):
    os.system("wget -q https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip")
    os.system("unzip -q v2_Questions_Train_mscoco.zip")
else:
    print("âœ… ì§ˆë¬¸ JSON ì¡´ì¬ - ë‹¤ìš´ë¡œë“œ ìƒëµ")

if not os.path.exists("v2_mscoco_train2014_annotations.json"):
    os.system("wget -q https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip")
    os.system("unzip -q v2_Annotations_Train_mscoco.zip")
else:
    print("âœ… ì •ë‹µ JSON ì¡´ì¬ - ë‹¤ìš´ë¡œë“œ ìƒëµ")

# ğŸ”¹ ë³€í™˜ CSV ìƒì„± (ì´ë¯¸ ì¡´ì¬ ì‹œ ìƒëµ)
if not os.path.exists("vqa_dacon_20k.csv"):
    import json, random
    import pandas as pd
    from tqdm import tqdm

    with open("v2_OpenEnded_mscoco_train2014_questions.json", "r") as f:
        questions = json.load(f)["questions"]

    with open("v2_mscoco_train2014_annotations.json", "r") as f:
        annotations = json.load(f)["annotations"]

    answer_map = {}
    for ann in annotations:
        answers = [a["answer"] for a in ann["answers"]]
        most_common = max(set(answers), key=answers.count)
        answer_map[ann["question_id"]] = most_common

    all_answers = list(answer_map.values())
    used_ids = set()
    converted = []

    def create_choices(correct, all_answers):
        options = list(set(all_answers) - {correct})
        random.shuffle(options)
        options = options[:3] + [correct]
        random.shuffle(options)
        labels = ["A", "B", "C", "D"]
        label_map = {l: o for l, o in zip(labels, options)}
        correct_label = next(k for k, v in label_map.items() if v == correct)
        return label_map, correct_label

    for q in tqdm(questions):
        qid = q["question_id"]
        img_id = q["image_id"]
        if qid not in answer_map or img_id in used_ids:
            continue

        label_map, correct_label = create_choices(answer_map[qid], all_answers)
        converted.append({
            "image": f"COCO_train2014_{img_id:012d}.jpg",
            "question": q["question"],
            "A": label_map["A"],
            "B": label_map["B"],
            "C": label_map["C"],
            "D": label_map["D"],
            "answer": correct_label
        })
        used_ids.add(img_id)

        if len(used_ids) >= 30000:
            break

    df = pd.DataFrame(converted)
    df.to_csv("vqa_dacon_20k.csv", index=False)
    print("âœ… vqa_dacon_20k.csv ìƒì„± ì™„ë£Œ")
else:
    print("âœ… vqa_dacon_20k.csv ì¡´ì¬ - ë³€í™˜ ìƒëµ")

"""ğŸ”¹ 3ë‹¨ê³„: í•™ìŠµìš© Dataset ì •ì˜"""

from PIL import Image
from torch.utils.data import Dataset

class VQADataset(Dataset):
    def __init__(self, csv_path, image_dir, processor):
        self.df = pd.read_csv(csv_path)
        self.image_dir = image_dir
        self.processor = processor
        self.label_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image = Image.open(f"{self.image_dir}/{row['image']}").convert("RGB")
        prompt = f"{row['question']} (A) {row['A']} (B) {row['B']} (C) {row['C']} (D) {row['D']}"
        inputs = self.processor(images=image, text=prompt, return_tensors="pt", padding="max_length", truncation=True, max_length=64)
        return {
            "input_ids": inputs.input_ids.squeeze(),
            "attention_mask": inputs.attention_mask.squeeze(),
            "pixel_values": inputs.pixel_values.squeeze(),
            "label": torch.tensor(self.label_map[row["answer"]])
        }

"""ğŸ”¹ 4ë‹¨ê³„: ëª¨ë¸ ë¡œë“œ + LoRA layer.0~11 ìë™ ì„¤ì •"""

import torch  # ë°˜ë“œì‹œ í•„ìš”
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from peft import LoraConfig, get_peft_model, TaskType

# ëª¨ë¸ ë¡œë“œ
model = Blip2ForConditionalGeneration.from_pretrained(
    "Salesforce/blip2-flan-t5-xl",
    device_map="auto",
    torch_dtype=torch.float16
)

# ğŸ”¥ LoRA íƒ€ê²Ÿ ëª¨ë“ˆ ìë™ ìƒì„± (layer.0 ~ layer.11 ì „ì²´)
target_modules = []
for i in range(12):
    target_modules += [
        f"qformer.encoder.layer.{i}.attention.attention.query",
        f"qformer.encoder.layer.{i}.attention.attention.value",
        f"qformer.encoder.layer.{i}.attention.output.dense",
        f"qformer.encoder.layer.{i}.crossattention.attention.query",
        f"qformer.encoder.layer.{i}.crossattention.attention.value",
    ]

# LoRA êµ¬ì„±
lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=target_modules,
    lora_dropout=0.1,
    bias="none",
    task_type=TaskType.FEATURE_EXTRACTION  # âœ… BLIP-2 êµ¬ì¡°ì— ì í•©
)

model = get_peft_model(model, lora_config)

"""ğŸ”¹ 5ë‹¨ê³„: compute_metrics í•¨ìˆ˜ ì •ì˜ (F1 í¬í•¨)"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = torch.tensor(logits).argmax(dim=1).numpy()
    labels = labels.numpy()

    return {
        "accuracy": accuracy_score(labels, preds),
        "precision": precision_score(labels, preds, average='macro'),
        "recall": recall_score(labels, preds, average='macro'),
        "f1": f1_score(labels, preds, average='macro')
    }

"""ğŸ”¹ 6ë‹¨ê³„: Trainer í•™ìŠµ ì½”ë“œ"""

# ğŸ”¹ processor ë¡œë“œ
processor = Blip2Processor.from_pretrained("Salesforce/blip2-flan-t5-xl")

# ğŸ”¹ train_dataset ì •ì˜
train_dataset = VQADataset(
    csv_path="vqa_dacon_20k.csv",     # ìƒì„±ëœ csv ê²½ë¡œ
    image_dir="train2014",         # ì´ë¯¸ì§€ í´ë” ê²½ë¡œ (ì„œë²„ì— ë³µì‚¬ë˜ì–´ ìˆì–´ì•¼ í•¨)
    processor=processor
)

from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./checkpoints",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=2,
    load_best_model_at_end=True,
    metric_for_best_model="f1",  # âœ… F1ì„ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
    greater_is_better=True,
    num_train_epochs=3,
    per_device_train_batch_size=4,
    fp16=True,
    logging_dir="./logs",
    logging_steps=10,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=train_dataset[:500],  # í‰ê°€ìš©
    tokenizer=processor,
    compute_metrics=compute_metrics
)

trainer.train()
