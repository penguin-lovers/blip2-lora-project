# -*- coding: utf-8 -*-
"""train
Automatically generated by Colab.
Original file is located at
    https://colab.research.google.com/drive/1zQ2lyKuqyaS7FEqsIXXVRdmjpTPRBSQN
"""

import os

# 🔹 COCO 이미지 다운로드 (이미 존재 시 생략)
if not os.path.exists("train2014"):
    os.system("pip install -q gdown")
    os.system("gdown --id 1FpLRZMeh2VL4pRjt5MVoZbTIhaJT4SOr")
    os.system("unzip -q train2014.zip -d train2014")
else:
    print("✅ train2014 디렉토리 존재 - 다운로드 생략")

# 🔹 질문/정답 JSON 다운로드 (이미 존재 시 생략)
if not os.path.exists("v2_OpenEnded_mscoco_train2014_questions.json"):
    os.system("wget -q https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip")
    os.system("unzip -q v2_Questions_Train_mscoco.zip")
else:
    print("✅ 질문 JSON 존재 - 다운로드 생략")

if not os.path.exists("v2_mscoco_train2014_annotations.json"):
    os.system("wget -q https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip")
    os.system("unzip -q v2_Annotations_Train_mscoco.zip")
else:
    print("✅ 정답 JSON 존재 - 다운로드 생략")

# 🔹 변환 CSV 생성 (이미 존재 시 생략)
if not os.path.exists("vqa_dacon_20k.csv"):
    import json, random
    import pandas as pd
    from tqdm import tqdm

    with open("v2_OpenEnded_mscoco_train2014_questions.json", "r") as f:
        questions = json.load(f)["questions"]

    with open("v2_mscoco_train2014_annotations.json", "r") as f:
        annotations = json.load(f)["annotations"]

    answer_map = {}
    for ann in annotations:
        answers = [a["answer"] for a in ann["answers"]]
        most_common = max(set(answers), key=answers.count)
        answer_map[ann["question_id"]] = most_common

    all_answers = list(answer_map.values())
    used_ids = set()
    converted = []

    def create_choices(correct, all_answers):
        options = list(set(all_answers) - {correct})
        random.shuffle(options)
        options = options[:3] + [correct]
        random.shuffle(options)
        labels = ["A", "B", "C", "D"]
        label_map = {l: o for l, o in zip(labels, options)}
        correct_label = next(k for k, v in label_map.items() if v == correct)
        return label_map, correct_label

    for q in tqdm(questions):
        qid = q["question_id"]
        img_id = q["image_id"]
        if qid not in answer_map or img_id in used_ids:
            continue

        label_map, correct_label = create_choices(answer_map[qid], all_answers)
        converted.append({
            "image": f"COCO_train2014_{img_id:012d}.jpg",
            "question": q["question"],
            "A": label_map["A"],
            "B": label_map["B"],
            "C": label_map["C"],
            "D": label_map["D"],
            "answer": correct_label
        })
        used_ids.add(img_id)

        if len(used_ids) >= 30000:
            break

    df = pd.DataFrame(converted)
    df.to_csv("vqa_dacon_20k.csv", index=False)
    print("✅ vqa_dacon_20k.csv 생성 완료")
else:
    print("✅ vqa_dacon_20k.csv 존재 - 변환 생략")

"""🔹 3단계: 학습용 Dataset 정의"""

from PIL import Image
from torch.utils.data import Dataset

class VQADataset(Dataset):
    def __init__(self, csv_path, image_dir, processor):
        self.df = pd.read_csv(csv_path)
        self.image_dir = image_dir
        self.processor = processor
        self.label_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image = Image.open(f"{self.image_dir}/{row['image']}").convert("RGB")
        prompt = f"{row['question']} (A) {row['A']} (B) {row['B']} (C) {row['C']} (D) {row['D']}"
        inputs = self.processor(images=image, text=prompt, return_tensors="pt", padding="max_length", truncation=True, max_length=64)
        return {
            "input_ids": inputs.input_ids.squeeze(),
            "attention_mask": inputs.attention_mask.squeeze(),
            "pixel_values": inputs.pixel_values.squeeze(),
            "label": torch.tensor(self.label_map[row["answer"]])
        }

"""🔹 4단계: 모델 로드 + LoRA layer.0~11 자동 설정"""

import torch  # 반드시 필요
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from peft import LoraConfig, get_peft_model, TaskType

# 모델 로드
model = Blip2ForConditionalGeneration.from_pretrained(
    "Salesforce/blip2-flan-t5-xl",
    device_map="auto",
    torch_dtype=torch.float16
)

# 🔥 LoRA 타겟 모듈 자동 생성 (layer.0 ~ layer.11 전체)
target_modules = []
for i in range(12):
    target_modules += [
        f"qformer.encoder.layer.{i}.attention.attention.query",
        f"qformer.encoder.layer.{i}.attention.attention.value",
        f"qformer.encoder.layer.{i}.attention.output.dense",
        f"qformer.encoder.layer.{i}.crossattention.attention.query",
        f"qformer.encoder.layer.{i}.crossattention.attention.value",
    ]

# LoRA 구성
lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=target_modules,
    lora_dropout=0.1,
    bias="none",
    task_type=TaskType.FEATURE_EXTRACTION  # ✅ BLIP-2 구조에 적합
)

model = get_peft_model(model, lora_config)

"""🔹 5단계: compute_metrics 함수 정의 (F1 포함)"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = torch.tensor(logits).argmax(dim=1).numpy()
    labels = labels.numpy()

    return {
        "accuracy": accuracy_score(labels, preds),
        "precision": precision_score(labels, preds, average='macro'),
        "recall": recall_score(labels, preds, average='macro'),
        "f1": f1_score(labels, preds, average='macro')
    }

"""🔹 6단계: Trainer 학습 코드"""

# 🔹 processor 로드
processor = Blip2Processor.from_pretrained("Salesforce/blip2-flan-t5-xl")

# 🔹 train_dataset 정의
train_dataset = VQADataset(
    csv_path="vqa_dacon_20k.csv",     # 생성된 csv 경로
    image_dir="train2014",         # 이미지 폴더 경로 (서버에 복사되어 있어야 함)
    processor=processor
)

from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./checkpoints",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=2,
    load_best_model_at_end=True,
    metric_for_best_model="f1",  # ✅ F1을 기준으로 저장
    greater_is_better=True,
    num_train_epochs=3,
    per_device_train_batch_size=4,
    fp16=True,
    logging_dir="./logs",
    logging_steps=10,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=train_dataset[:500],  # 평가용
    tokenizer=processor,
    compute_metrics=compute_metrics
)

trainer.train()
